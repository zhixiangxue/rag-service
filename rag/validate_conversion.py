#!/usr/bin/env python3
"""
PDF è½¬ Markdown è´¨é‡éªŒè¯å·¥å…·

è‡ªåŠ¨åŒ–éªŒè¯ PDF è½¬æ¢è´¨é‡ï¼ŒåŒ…æ‹¬ï¼š
1. ç»“æ„å®Œæ•´æ€§æ£€æŸ¥ï¼ˆç« èŠ‚ã€æ ‡é¢˜å±‚çº§ï¼‰
2. è¡¨æ ¼è´¨é‡åˆ†æ
3. å†…å®¹ç»Ÿè®¡å¯¹æ¯”
4. æ ¼å¼è§„èŒƒæ£€æŸ¥
5. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
"""

import re
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass, field
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
import fitz  # PyMuPDF

console = Console()


@dataclass
class ValidationMetrics:
    """éªŒè¯æŒ‡æ ‡æ•°æ®ç±»"""
    # åŸºç¡€ç»Ÿè®¡
    char_count: int = 0
    word_count: int = 0
    line_count: int = 0
    
    # ç»“æ„å…ƒç´ 
    heading_counts: Dict[int, int] = field(default_factory=dict)  # {level: count}
    table_count: int = 0
    list_count: int = 0
    
    # æ ¼å¼é—®é¢˜
    broken_tables: List[str] = field(default_factory=list)
    malformed_headings: List[str] = field(default_factory=list)
    encoding_issues: List[str] = field(default_factory=list)
    
    # PDF ç‰¹æœ‰
    page_count: int = 0
    pdf_tables: int = 0


class MarkdownValidator:
    """Markdown è´¨é‡éªŒè¯å™¨"""
    
    def __init__(self, md_path: Path):
        self.md_path = md_path
        self.content = md_path.read_text(encoding='utf-8')
        self.lines = self.content.split('\n')
        self.metrics = ValidationMetrics()
    
    def validate(self) -> ValidationMetrics:
        """æ‰§è¡Œå®Œæ•´éªŒè¯"""
        console.print(f"\n[cyan]ğŸ“ éªŒè¯ Markdown: {self.md_path.name}[/cyan]")
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("[cyan]åˆ†æä¸­...", total=6)
            
            self._count_basic_stats()
            progress.update(task, advance=1)
            
            self._analyze_headings()
            progress.update(task, advance=1)
            
            self._analyze_tables()
            progress.update(task, advance=1)
            
            self._analyze_lists()
            progress.update(task, advance=1)
            
            self._check_format_issues()
            progress.update(task, advance=1)
            
            self._check_encoding()
            progress.update(task, advance=1)
        
        return self.metrics
    
    def _count_basic_stats(self):
        """ç»Ÿè®¡åŸºç¡€æŒ‡æ ‡"""
        self.metrics.char_count = len(self.content)
        self.metrics.word_count = len(re.findall(r'\b\w+\b', self.content))
        self.metrics.line_count = len(self.lines)
    
    def _analyze_headings(self):
        """åˆ†ææ ‡é¢˜ç»“æ„"""
        heading_pattern = re.compile(r'^(#{1,6})\s+(.+)$')
        
        for i, line in enumerate(self.lines, 1):
            match = heading_pattern.match(line)
            if match:
                level = len(match.group(1))
                self.metrics.heading_counts[level] = self.metrics.heading_counts.get(level, 0) + 1
                
                # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦è§„èŒƒ
                title = match.group(2).strip()
                if not title:
                    self.metrics.malformed_headings.append(f"ç¬¬ {i} è¡Œ: ç©ºæ ‡é¢˜")
                elif len(title) > 200:
                    self.metrics.malformed_headings.append(f"ç¬¬ {i} è¡Œ: æ ‡é¢˜è¿‡é•¿ ({len(title)} å­—ç¬¦)")
    
    def _analyze_tables(self):
        """åˆ†æè¡¨æ ¼è´¨é‡"""
        in_table = False
        table_lines = []
        table_start = 0
        
        for i, line in enumerate(self.lines, 1):
            is_table_line = bool(re.match(r'^\|.*\|$', line))
            
            if is_table_line:
                if not in_table:
                    in_table = True
                    table_start = i
                    table_lines = [line]
                else:
                    table_lines.append(line)
            elif in_table:
                # è¡¨æ ¼ç»“æŸï¼ŒéªŒè¯è´¨é‡
                in_table = False
                self.metrics.table_count += 1
                self._validate_table(table_lines, table_start)
                table_lines = []
        
        # å¤„ç†æ–‡ä»¶æœ«å°¾çš„è¡¨æ ¼
        if in_table:
            self.metrics.table_count += 1
            self._validate_table(table_lines, table_start)
    
    def _validate_table(self, lines: List[str], start_line: int):
        """éªŒè¯å•ä¸ªè¡¨æ ¼çš„è´¨é‡"""
        if len(lines) < 2:
            self.metrics.broken_tables.append(
                f"ç¬¬ {start_line} è¡Œ: è¡¨æ ¼è¡Œæ•°è¿‡å°‘ ({len(lines)} è¡Œ)"
            )
            return
        
        # æ£€æŸ¥åˆ—æ•°ä¸€è‡´æ€§ï¼ˆæ­£ç¡®å¤„ç†ç©ºåˆ—ï¼‰
        col_counts = []
        for line in lines:
            # åˆ†å‰²åï¼Œç§»é™¤é¦–å°¾çš„ç©ºå­—ç¬¦ä¸²ï¼ˆ| å‰åçš„ï¼‰
            cols = line.split('|')
            # åªç§»é™¤é¦–å°¾ï¼Œä¸­é—´çš„ç©ºæ ¼ä¿ç•™
            if cols and cols[0] == '':
                cols = cols[1:]
            if cols and cols[-1] == '':
                cols = cols[:-1]
            col_counts.append(len(cols))
        
        # å…è®¸ Â±1 åˆ—çš„è¯¯å·®ï¼ˆå› ä¸º Markdown è¡¨æ ¼æ ¼å¼çµæ´»ï¼‰
        min_cols = min(col_counts)
        max_cols = max(col_counts)
        
        if max_cols - min_cols > 1:
            self.metrics.broken_tables.append(
                f"ç¬¬ {start_line} è¡Œ: è¡¨æ ¼åˆ—æ•°å·®å¼‚è¾ƒå¤§ (æœ€å°‘{min_cols}åˆ—, æœ€å¤š{max_cols}åˆ—)"
            )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†éš”çº¿
        has_separator = any('---' in line or 'â”' in line or 'â”€' in line for line in lines[:3])
        if not has_separator and len(lines) > 2:
            # ä¸æŠ¥å‘Šç¼ºå°‘åˆ†éš”çº¿ï¼Œå› ä¸ºæœ‰äº›è¡¨æ ¼ç¡®å®æ²¡æœ‰
            pass
    
    def _analyze_lists(self):
        """åˆ†æåˆ—è¡¨"""
        list_pattern = re.compile(r'^\s*[-*+]\s+\S')
        self.metrics.list_count = sum(1 for line in self.lines if list_pattern.match(line))
    
    def _check_format_issues(self):
        """æ£€æŸ¥æ ¼å¼é—®é¢˜"""
        for i, line in enumerate(self.lines, 1):
            # æ£€æŸ¥è¿ç»­å¤šä¸ªç©ºè¡Œ
            if i > 1 and not line.strip() and not self.lines[i-2].strip():
                pass  # æš‚ä¸æŠ¥å‘Šï¼Œå¤ªå¸¸è§
            
            # æ£€æŸ¥è¡Œæœ«ç©ºæ ¼ï¼ˆå¯èƒ½å½±å“ Markdown æ¸²æŸ“ï¼‰
            if line.endswith(' ' * 3):
                pass  # Markdown çš„æ¢è¡Œè¯­æ³•ï¼Œæ­£å¸¸
    
    def _check_encoding(self):
        """æ£€æŸ¥ç¼–ç é—®é¢˜"""
        problematic_chars = ['ï¿½', '\ufffd', '\x00']
        
        for i, line in enumerate(self.lines, 1):
            for char in problematic_chars:
                if char in line:
                    preview = line[:50].replace('\n', ' ')
                    self.metrics.encoding_issues.append(
                        f"ç¬¬ {i} è¡Œ: ç¼–ç é—®é¢˜å­—ç¬¦ '{char}' - {preview}..."
                    )
                    break


class PDFAnalyzer:
    """PDF æ–‡æ¡£åˆ†æå™¨"""
    
    def __init__(self, pdf_path: Path):
        self.pdf_path = pdf_path
        self.metrics = ValidationMetrics()
    
    def analyze(self) -> ValidationMetrics:
        """åˆ†æ PDF æ–‡æ¡£"""
        console.print(f"\n[cyan]ğŸ“„ åˆ†æ PDF: {self.pdf_path.name}[/cyan]")
        
        try:
            doc = fitz.open(self.pdf_path)
            self.metrics.page_count = len(doc)
            
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console
            ) as progress:
                task = progress.add_task(
                    "[cyan]æå– PDF ä¿¡æ¯...", 
                    total=len(doc)
                )
                
                total_chars = 0
                total_words = 0
                
                for page_num, page in enumerate(doc, 1):
                    text = page.get_text()
                    total_chars += len(text)
                    total_words += len(re.findall(r'\b\w+\b', text))
                    
                    # ç»Ÿè®¡è¡¨æ ¼ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
                    try:
                        tables = page.find_tables()
                        if tables and hasattr(tables, '__iter__'):
                            self.metrics.pdf_tables += len(list(tables))
                    except:
                        pass  # å¿½ç•¥è¡¨æ ¼æ£€æµ‹é”™è¯¯
                    
                    progress.update(task, advance=1)
                
                self.metrics.char_count = total_chars
                self.metrics.word_count = total_words
            
            doc.close()
            
        except Exception as e:
            console.print(f"[red]âŒ PDF åˆ†æå¤±è´¥: {e}[/red]")
        
        return self.metrics


class ConversionValidator:
    """è½¬æ¢è´¨é‡éªŒè¯å™¨"""
    
    def __init__(self, pdf_path: Path, md_path: Path):
        self.pdf_path = pdf_path
        self.md_path = md_path
    
    def validate(self):
        """æ‰§è¡Œå®Œæ•´éªŒè¯æµç¨‹"""
        console.print("\n" + "=" * 70)
        console.print("  ğŸ” PDF è½¬ Markdown è´¨é‡éªŒè¯", style="bold cyan")
        console.print("=" * 70)
        
        # åˆ†æ PDF
        pdf_analyzer = PDFAnalyzer(self.pdf_path)
        pdf_metrics = pdf_analyzer.analyze()
        
        # éªŒè¯ Markdown
        md_validator = MarkdownValidator(self.md_path)
        md_metrics = md_validator.validate()
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report(pdf_metrics, md_metrics)
    
    def _generate_report(self, pdf: ValidationMetrics, md: ValidationMetrics):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        console.print("\n" + "=" * 70)
        console.print("  ğŸ“Š éªŒè¯æŠ¥å‘Š", style="bold green")
        console.print("=" * 70)
        
        # 1. åŸºç¡€ç»Ÿè®¡å¯¹æ¯”
        self._print_basic_stats(pdf, md)
        
        # 2. ç»“æ„åˆ†æ
        self._print_structure_analysis(md)
        
        # 3. é—®é¢˜æ±‡æ€»
        self._print_issues(md)
        
        # 4. æ•´ä½“è¯„åˆ†
        self._print_score(pdf, md)
    
    def _print_basic_stats(self, pdf: ValidationMetrics, md: ValidationMetrics):
        """æ‰“å°åŸºç¡€ç»Ÿè®¡å¯¹æ¯”"""
        table = Table(title="ğŸ“ˆ åŸºç¡€ç»Ÿè®¡å¯¹æ¯”", show_header=True)
        table.add_column("æŒ‡æ ‡", style="cyan", width=20)
        table.add_column("PDF", style="yellow", justify="right", width=15)
        table.add_column("Markdown", style="green", justify="right", width=15)
        table.add_column("ä¿ç•™ç‡", style="magenta", justify="right", width=15)
        
        # é¡µæ•°/è¡Œæ•°
        table.add_row(
            "é¡µæ•°/è¡Œæ•°",
            f"{pdf.page_count:,} é¡µ",
            f"{md.line_count:,} è¡Œ",
            "N/A"
        )
        
        # å­—ç¬¦æ•°
        char_rate = (md.char_count / pdf.char_count * 100) if pdf.char_count > 0 else 0
        table.add_row(
            "å­—ç¬¦æ•°",
            f"{pdf.char_count:,}",
            f"{md.char_count:,}",
            f"{char_rate:.1f}%"
        )
        
        # å•è¯æ•°
        word_rate = (md.word_count / pdf.word_count * 100) if pdf.word_count > 0 else 0
        table.add_row(
            "å•è¯æ•°",
            f"{pdf.word_count:,}",
            f"{md.word_count:,}",
            f"{word_rate:.1f}%"
        )
        
        # è¡¨æ ¼æ•°
        if pdf.pdf_tables > 0:
            table_rate = (md.table_count / pdf.pdf_tables * 100)
            table.add_row(
                "è¡¨æ ¼æ•°",
                f"{pdf.pdf_tables:,}",
                f"{md.table_count:,}",
                f"{table_rate:.1f}%"
            )
        
        console.print(table)
    
    def _print_structure_analysis(self, md: ValidationMetrics):
        """æ‰“å°ç»“æ„åˆ†æ"""
        console.print("\n[bold cyan]ğŸ“š æ–‡æ¡£ç»“æ„åˆ†æ[/bold cyan]")
        
        table = Table(show_header=True)
        table.add_column("å…ƒç´ ç±»å‹", style="cyan", width=20)
        table.add_column("æ•°é‡", style="green", justify="right", width=15)
        
        # æ ‡é¢˜å±‚çº§
        if md.heading_counts:
            for level in sorted(md.heading_counts.keys()):
                table.add_row(
                    f"{'#' * level} æ ‡é¢˜ (H{level})",
                    f"{md.heading_counts[level]:,}"
                )
        
        # è¡¨æ ¼
        table.add_row("è¡¨æ ¼", f"{md.table_count:,}")
        
        # åˆ—è¡¨
        table.add_row("åˆ—è¡¨é¡¹", f"{md.list_count:,}")
        
        console.print(table)
    
    def _print_issues(self, md: ValidationMetrics):
        """æ‰“å°é—®é¢˜æ±‡æ€»"""
        console.print("\n[bold yellow]âš ï¸  é—®é¢˜æ±‡æ€»[/bold yellow]")
        
        total_issues = (
            len(md.broken_tables) + 
            len(md.malformed_headings) + 
            len(md.encoding_issues)
        )
        
        if total_issues == 0:
            console.print("[green]âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜[/green]")
            return
        
        # è¡¨æ ¼é—®é¢˜
        if md.broken_tables:
            console.print(f"\n[red]âŒ è¡¨æ ¼é—®é¢˜ ({len(md.broken_tables)} ä¸ª):[/red]")
            for issue in md.broken_tables[:5]:
                console.print(f"   â€¢ {issue}")
            if len(md.broken_tables) > 5:
                console.print(f"   ... è¿˜æœ‰ {len(md.broken_tables) - 5} ä¸ªé—®é¢˜")
        
        # æ ‡é¢˜é—®é¢˜
        if md.malformed_headings:
            console.print(f"\n[yellow]âš ï¸  æ ‡é¢˜é—®é¢˜ ({len(md.malformed_headings)} ä¸ª):[/yellow]")
            for issue in md.malformed_headings[:5]:
                console.print(f"   â€¢ {issue}")
            if len(md.malformed_headings) > 5:
                console.print(f"   ... è¿˜æœ‰ {len(md.malformed_headings) - 5} ä¸ªé—®é¢˜")
        
        # ç¼–ç é—®é¢˜
        if md.encoding_issues:
            console.print(f"\n[red]âŒ ç¼–ç é—®é¢˜ ({len(md.encoding_issues)} ä¸ª):[/red]")
            for issue in md.encoding_issues[:3]:
                console.print(f"   â€¢ {issue}")
            if len(md.encoding_issues) > 3:
                console.print(f"   ... è¿˜æœ‰ {len(md.encoding_issues) - 3} ä¸ªé—®é¢˜")
    
    def _print_score(self, pdf: ValidationMetrics, md: ValidationMetrics):
        """æ‰“å°æ•´ä½“è¯„åˆ†"""
        console.print("\n[bold magenta]ğŸ¯ è´¨é‡è¯„åˆ†[/bold magenta]")
        
        # è®¡ç®—å„é¡¹å¾—åˆ†
        scores = {}
        
        # 1. å†…å®¹å®Œæ•´æ€§ (40åˆ†)
        char_rate = (md.char_count / pdf.char_count) if pdf.char_count > 0 else 0
        content_score = min(40, char_rate * 40)
        scores['å†…å®¹å®Œæ•´æ€§'] = (content_score, 40, char_rate * 100)
        
        # 2. ç»“æ„å®Œæ•´æ€§ (30åˆ†)
        structure_score = 30
        if md.heading_counts:
            structure_score = 30
        elif md.table_count == 0:
            structure_score = 15
        scores['ç»“æ„å®Œæ•´æ€§'] = (structure_score, 30, structure_score / 30 * 100)
        
        # 3. æ ¼å¼è§„èŒƒæ€§ (30åˆ†)
        issue_count = (
            len(md.broken_tables) + 
            len(md.malformed_headings) + 
            len(md.encoding_issues)
        )
        format_score = max(0, 30 - issue_count * 2)
        scores['æ ¼å¼è§„èŒƒæ€§'] = (format_score, 30, format_score / 30 * 100)
        
        # æ‰“å°å¾—åˆ†è¡¨
        table = Table(show_header=True)
        table.add_column("è¯„åˆ†é¡¹", style="cyan", width=20)
        table.add_column("å¾—åˆ†", style="green", justify="right", width=10)
        table.add_column("æ»¡åˆ†", style="yellow", justify="right", width=10)
        table.add_column("ç™¾åˆ†æ¯”", style="magenta", justify="right", width=15)
        
        for name, (score, max_score, percentage) in scores.items():
            table.add_row(
                name,
                f"{score:.1f}",
                f"{max_score}",
                f"{percentage:.1f}%"
            )
        
        total_score = sum(s[0] for s in scores.values())
        total_max = sum(s[1] for s in scores.values())
        
        table.add_row(
            "[bold]æ€»åˆ†[/bold]",
            f"[bold]{total_score:.1f}[/bold]",
            f"[bold]{total_max}[/bold]",
            f"[bold]{total_score / total_max * 100:.1f}%[/bold]"
        )
        
        console.print(table)
        
        # è¯„çº§
        if total_score >= 90:
            grade = "ä¼˜ç§€ ğŸ‰"
            style = "bold green"
        elif total_score >= 75:
            grade = "è‰¯å¥½ ğŸ‘"
            style = "bold cyan"
        elif total_score >= 60:
            grade = "åŠæ ¼ âœ“"
            style = "bold yellow"
        else:
            grade = "éœ€æ”¹è¿› âš ï¸"
            style = "bold red"
        
        console.print(f"\n[{style}]è´¨é‡è¯„çº§: {grade}[/{style}]")


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # ä½¿ç”¨ç¤ºä¾‹
    output_dir = Path(__file__).parent / "output"
    files_dir = Path(__file__).parent / "files"
    
    # æŸ¥æ‰¾æ‰€æœ‰ PDF å’Œå¯¹åº”çš„ MD æ–‡ä»¶
    pdf_files = list(files_dir.glob("*.pdf"))
    
    if not pdf_files:
        console.print("[red]âŒ æœªæ‰¾åˆ° PDF æ–‡ä»¶[/red]")
        sys.exit(1)
    
    for pdf_path in pdf_files:
        md_path = output_dir / f"{pdf_path.stem}.md"
        
        if not md_path.exists():
            console.print(f"[yellow]âš ï¸  è·³è¿‡ {pdf_path.name}: æœªæ‰¾åˆ°å¯¹åº”çš„ MD æ–‡ä»¶[/yellow]")
            continue
        
        validator = ConversionValidator(pdf_path, md_path)
        validator.validate()
        
        console.print("\n")


def validate_cache_quality(pdf_path: Path, md_path: Path, threshold: float = 90.0, verbose: bool = False) -> bool:
    """
    éªŒè¯ç¼“å­˜æ–‡ä»¶è´¨é‡
    
    Args:
        pdf_path: PDF æ–‡ä»¶è·¯å¾„
        md_path: Markdown æ–‡ä»¶è·¯å¾„
        threshold: è´¨é‡é˜ˆå€¼ï¼ˆé»˜è®¤ 90 åˆ†ï¼‰
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        
    Returns:
        bool: True è¡¨ç¤ºç¼“å­˜è´¨é‡åˆæ ¼ï¼ŒFalse è¡¨ç¤ºéœ€è¦é‡æ–°ç”Ÿæˆ
    """
    if not md_path.exists():
        return False
    
    try:
        # åˆ†æ PDF
        pdf_analyzer = PDFAnalyzer(pdf_path)
        pdf_metrics = pdf_analyzer.analyze() if verbose else _analyze_pdf_silent(pdf_path)
        
        # éªŒè¯ Markdown
        md_validator = MarkdownValidator(md_path)
        md_metrics = md_validator.validate() if verbose else _validate_markdown_silent(md_path)
        
        # è®¡ç®—æ€»åˆ†
        score = _calculate_quality_score(pdf_metrics, md_metrics)
        
        if verbose:
            if score >= threshold:
                console.print(f"[green]âœ… ç¼“å­˜è´¨é‡åˆæ ¼: {score:.1f}/100[/green]")
            else:
                console.print(f"[yellow]âš ï¸  ç¼“å­˜è´¨é‡ä¸è¶³: {score:.1f}/100 (é˜ˆå€¼: {threshold})[/yellow]")
        
        return score >= threshold
        
    except Exception as e:
        if verbose:
            console.print(f"[red]âŒ éªŒè¯å¤±è´¥: {e}[/red]")
        return False


def _analyze_pdf_silent(pdf_path: Path) -> ValidationMetrics:
    """é™é»˜åˆ†æ PDFï¼ˆä¸è¾“å‡ºï¼‰"""
    metrics = ValidationMetrics()
    try:
        doc = fitz.open(pdf_path)
        metrics.page_count = len(doc)
        
        total_chars = 0
        total_words = 0
        
        for page in doc:
            text = page.get_text()
            total_chars += len(text)
            total_words += len(re.findall(r'\b\w+\b', text))
        
        metrics.char_count = total_chars
        metrics.word_count = total_words
        doc.close()
    except Exception:
        pass
    
    return metrics


def _validate_markdown_silent(md_path: Path) -> ValidationMetrics:
    """é™é»˜éªŒè¯ Markdownï¼ˆä¸è¾“å‡ºï¼‰"""
    metrics = ValidationMetrics()
    try:
        content = md_path.read_text(encoding='utf-8')
        lines = content.split('\n')
        
        # åŸºç¡€ç»Ÿè®¡
        metrics.char_count = len(content)
        metrics.word_count = len(re.findall(r'\b\w+\b', content))
        metrics.line_count = len(lines)
        
        # æ ‡é¢˜ç»Ÿè®¡
        heading_pattern = re.compile(r'^(#{1,6})\s+(.+)$')
        for line in lines:
            match = heading_pattern.match(line)
            if match:
                level = len(match.group(1))
                metrics.heading_counts[level] = metrics.heading_counts.get(level, 0) + 1
                title = match.group(2).strip()
                if not title or len(title) > 200:
                    metrics.malformed_headings.append("")
        
        # è¡¨æ ¼ç»Ÿè®¡
        in_table = False
        table_lines = []
        for line in lines:
            is_table_line = bool(re.match(r'^\|.*\|$', line))
            if is_table_line:
                if not in_table:
                    in_table = True
                    table_lines = [line]
                else:
                    table_lines.append(line)
            elif in_table:
                metrics.table_count += 1
                # ç®€åŒ–éªŒè¯
                if len(table_lines) >= 2:
                    col_counts = []
                    for tline in table_lines:
                        cols = tline.split('|')
                        if cols and cols[0] == '':
                            cols = cols[1:]
                        if cols and cols[-1] == '':
                            cols = cols[:-1]
                        col_counts.append(len(cols))
                    if max(col_counts) - min(col_counts) > 1:
                        metrics.broken_tables.append("")
                in_table = False
                table_lines = []
        
        if in_table:
            metrics.table_count += 1
        
        # ç¼–ç æ£€æŸ¥
        problematic_chars = ['ï¿½', '\ufffd', '\x00']
        for line in lines:
            if any(char in line for char in problematic_chars):
                metrics.encoding_issues.append("")
                break
    
    except Exception:
        pass
    
    return metrics


def _calculate_quality_score(pdf: ValidationMetrics, md: ValidationMetrics) -> float:
    """
    è®¡ç®—è´¨é‡å¾—åˆ†
    
    Args:
        pdf: PDF æŒ‡æ ‡
        md: Markdown æŒ‡æ ‡
        
    Returns:
        float: è´¨é‡å¾—åˆ† (0-100)
    """
    # 1. å†…å®¹å®Œæ•´æ€§ (40åˆ†)
    char_rate = (md.char_count / pdf.char_count) if pdf.char_count > 0 else 0
    content_score = min(40, char_rate * 40)
    
    # 2. ç»“æ„å®Œæ•´æ€§ (30åˆ†)
    structure_score = 30
    if not md.heading_counts:
        structure_score = 15
    elif md.table_count == 0:
        structure_score = 20
    
    # 3. æ ¼å¼è§„èŒƒæ€§ (30åˆ†)
    issue_count = (
        len(md.broken_tables) + 
        len(md.malformed_headings) + 
        len(md.encoding_issues)
    )
    format_score = max(0, 30 - issue_count * 2)
    
    total_score = content_score + structure_score + format_score
    return total_score


if __name__ == "__main__":
    main()
